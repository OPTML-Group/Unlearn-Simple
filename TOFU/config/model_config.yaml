llama2-7b:
  hf_key: "NousResearch/Llama-2-7b-chat-hf"
  question_start_tag: "[INST] "
  question_end_tag: " [/INST]"
  answer_tag: ""
  flash_attention2: "true"
  gradient_checkpointing: "true"
  # ft_model_path: "paper_models/final_ft_noLORA_5_epochs_inst_lr1e-05_llama2-7b_full/checkpoint-625" #this model will be used for unlearning by defauly
  ft_model_path: "locuslab/tofu_ft_llama2-7b"
phi:
  hf_key: "microsoft/phi-1_5"
  question_start_tag: "Question: "
  question_end_tag: "\n"
  answer_tag: "Answer: "
  flash_attention2: "false"
  gradient_checkpointing: "false"
  ft_model_path: "paper_models/final_ft_noLORA_5_epochs_inst_lr2e-05_phi_full/checkpoint-625"
stablelm:
  hf_key: "stabilityai/stablelm-3b-4e1t"
  question_start_tag: "Question: "
  question_end_tag: "\n"
  answer_tag: "Answer: "
  flash_attention2: "false"
  gradient_checkpointing: "false"
  ft_model_path: "paper_models/final_ft_noLORA_5_epochs_inst_lr1e-05_stablelm/checkpoint-625"
pythia-1.4:
  hf_key: "EleutherAI/pythia-1.4b-deduped"
  question_start_tag: "Question: "
  question_end_tag: "\n"
  answer_tag: "Answer: "
  flash_attention2: "false"
  gradient_checkpointing: "false"
zephyr-7b-beta:
  hf_key: "HuggingFaceH4/zephyr-7b-beta"
  flash_attention2: "true"
  gradient_checkpointing: "true"
  
